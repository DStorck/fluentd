image:
  repository: gcr.io/google-containers/fluentd-elasticsearch
  tag: v2.3.1
  pullPolicy: IfNotPresent

output:
  host: elasticsearch
  port: 9200
  buffer_chunk_limit: 2M
  buffer_queue_limit: 8
  scheme: http

env: {}

fluentESUser: elastic 
fluentESPassword: changeme 

awsSecKey: secretKey 
awsKeyId: keyId

s3Bucket: sampleBucketName
s3Region: sampleBucketRegion

service:
  type: ClusterIP
  externalPort: 80
  ports:
    - name: "monitor-agent"
      protocol: TCP
      containerPort: 24220

  annotations:
    # kubernetes.io/tls-acme: "true"
  tls:
    # Secrets must be manually created in the namespace.
    # - secretName: http-input-tls
    #   hosts:
    #     - http-input.local

configMaps:
  general.conf: |
    # Prevent fluentd from handling records containing its own logs. Otherwise
    # it can lead to an infinite loop, when error in sending one message generates
    # another message which also fails to be sent and so on.
    <match fluentd.**>
      @type null
    </match>
    # Used for health checking
    # <source>
    #   @type http
    #   port 9880
    #   bind 0.0.0.0
    # </source>
    # Emits internal metrics to every minute, and also exposes them on port
    # 24220. Useful for determining if an output plugin is retryring/erroring,
    # or determining the buffer queue length.
    # <source>
    #   @type monitor_agent
    #   bind 0.0.0.0
    #   port 24220
    #   tag fluentd.monitor.metrics
    # </source>
  system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
    </system>
  forward-input.conf: |
    <source>
      @type dummy
      tag dummy 
      dummy {"hello":" taco"}
    </source>
    
    <source>
      @type forward
      port 24220
      @log_level debug 
      allow_self_signed_certificate true
      <transport tls>
         ca_path                /fluentd/etc/ssl/ca.crt.pem
         cert_path              /fluentd/etc/ssl/server.crt.pem
         private_key_path       /fluentd/etc/ssl/server.key.pem
         private_key_passphrase "fbit"
         client_cert_auth       true
      </transport>
      <security>
        self_hostname fluentd
        shared_key fluentd
      </security>
    </source>
    
    <match **>
      @type stdout
    </match>
    <match fluent_bit>
      @type stdout
    </match>
    
  output.conf: |
    <match host.**>
      @type copy
      <store>
        @type elasticsearch
        @log_level info
        port 9200
        include_tag_key true
        tag_key @log_name
        logstash_format true
        logstash_prefix logsystemd
        flush_interval 10s
        max_retry_wait 30
        disable_retry_limit
        host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
        port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
        user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
        password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
      </store>
      <store>
        @type s3
        aws_key_id "#{ENV['AWS_KEY_ID']}"
        aws_sec_key "#{ENV['AWS_SECRET_KEY']}"
        s3_bucket "#{ENV['S3_BUCKET']}"
        s3_region "#{ENV['S3_REGION']}"
        path logs/
        buffer_path /var/log/fluent/s3
        time_slice_format %Y%m%d%H
        time_slice_wait 28m
        utc
        buffer_chunk_limit 256m
      </store>
    </match>
    
    <match **>
      @type copy
      <store>
        @type elasticsearch
        @log_level info
        port 9200
        include_tag_key true
        tag_key @log_name
        logstash_format true
        flush_interval 10s
        max_retry_wait 30
        disable_retry_limit
        host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
        port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
        user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
        password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
      </store>
      <store>
        @type s3
        @log_level debug
        aws_key_id "#{ENV['AWS_KEY_ID']}"
        aws_sec_key "#{ENV['AWS_SECRET_KEY']}"
        s3_bucket "#{ENV['S3_BUCKET']}"
        s3_region "#{ENV['S3_REGION']}"
        path logs/
        buffer_path /var/log/fluent/s3
        time_slice_format %Y%m%d%H
        time_slice_wait 28m
        utc
        buffer_chunk_limit 256m
      </store>
    </match>

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 500m
  #  memory: 200Mi
  # requests:
  #  cpu: 500m
  #  memory: 200Mi

## Persist data to a persistent volume
persistence:
  enabled: false

  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  # annotations: {}
  accessMode: ReadWriteOnce
  size: 10Gi

nodeSelector: {}

tolerations: []

affinity: {}